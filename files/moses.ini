# MERT optimized configuration
# decoder /export/home/s14/niyongabopp/mosesdecoder/bin/moses
# BLEU 0.811884 on dev /export/home/s14/niyongabopp/corpus/train.true.en
# We were before running iteration 5
# finished Mon Dec 12 14:25:47 CST 2016
### MOSES CONFIG FILE ###
#########################

# input factors
[input-factors]
0

# mapping steps
[mapping]
0 T 0

[distortion-limit]
6

# feature functions
[feature]
UnknownWordPenalty
WordPenalty
PhrasePenalty
PhraseDictionaryMemory name=TranslationModel0 num-features=4 path=/export/home/s14/niyongabopp/working/train/model/phrase-table.gz input-factor=0 output-factor=0
LexicalReordering name=LexicalReordering0 num-features=6 type=wbe-msd-bidirectional-fe-allff input-factor=0 output-factor=0 path=/export/home/s14/niyongabopp/working/train/model/reordering-table.wbe-msd-bidirectional-fe.gz
Distortion
KENLM name=LM0 factor=0 path=/export/home/s14/niyongabopp//lm/bible.en-kn.blm.kn order=3

# dense weights for feature functions
[weight]

LexicalReordering0= 0.0511426 0.0255929 0.0391846 -0.280932 0.0141974 0.0215455
Distortion0= 0.112974
LM0= 0.0269908
WordPenalty0= 0.0333231
PhrasePenalty0= 0.0332891
TranslationModel0= 0.0467293 0.0066613 0.0107129 0.296725
UnknownWordPenalty0= 1
